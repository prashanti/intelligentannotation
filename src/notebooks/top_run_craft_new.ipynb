{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_run_intelligent_OA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from networkx.algorithms.traversal.depth_first_search import dfs_tree\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import networkx as nx\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # type: ignore\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Dense, TimeDistributed, Dropout,\\\n",
        "    Bidirectional, concatenate, SpatialDropout1D, GRU\n",
        "from tensorflow.keras.utils import to_categorical  # type: ignore"
      ],
      "metadata": {
        "id": "4j8i0I_TMdGZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "logging.basicConfig(\n",
        "    filename='craft.log',\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')"
      ],
      "metadata": {
        "id": "7crBNdkzMgC7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
        "BASE_DIR = '/content/drive/MyDrive/NEMO'\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"model_output\", \"Experiments\")\n",
        "DATASET_LOC = os.path.join(DATA_DIR, \"model_input\", \"dataset\")\n",
        "direct_parent = os.path.join(DATA_DIR, \"GO_Category\", \"GO_DirectParents.tsv\")\n",
        "\n",
        "go_category = [\"GO:0008150\", \"GO:0005575\", \"GO:0003674\"]"
      ],
      "metadata": {
        "id": "7BIaEXTZMkB0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sim(term1, term2):\n",
        "    if \"GO\" in term1 and \"GO\" in term2:\n",
        "        term1 = term1.replace(\"B-\", \"\").replace(\"I-\", \"\")\n",
        "        term2 = term2.replace(\"B-\", \"\").replace(\"I-\", \"\")\n",
        "        t1 = set(subsumers.get(term1, term1))\n",
        "        t2 = set(subsumers.get(term2, term2))\n",
        "        if len(set.union(t1, t2)) > 0:\n",
        "            simj = len(set.intersection(t1, t2)) / len(set.union(t1, t2))\n",
        "        else:\n",
        "            simj = 0.0\n",
        "    else:\n",
        "        simj = 0.0\n",
        "    return simj"
      ],
      "metadata": {
        "id": "99O-aWdEMm4e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer(opt, lr):\n",
        "    if opt == 'adam':\n",
        "        return tf.keras.optimizers.Adam(\n",
        "            learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
        "    elif opt == 'adamw':\n",
        "        step = tf.Variable(0, trainable=False)\n",
        "        schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "            [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
        "        # lr and wd can be a function or a tensor\n",
        "        lr = lr * schedule(step)\n",
        "\n",
        "        def wd():\n",
        "            return 1e-4 * schedule(step)\n",
        "        # wd = lambda: 1e-4 * schedule(step)  # type: ignore\n",
        "        return tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
        "    elif opt == 'rmsprop':\n",
        "        return tf.keras.optimizers.RMSprop(learning_rate=lr)"
      ],
      "metadata": {
        "id": "kG8xQDTjMobk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(loss):\n",
        "    if 'categoricalCE' in loss:\n",
        "        if 'logits' in loss:\n",
        "            return tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "        else:\n",
        "            return tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "    elif 'sigfocalCE' in loss:\n",
        "        if 'logits' in loss:\n",
        "            return tfa.losses.SigmoidFocalCrossEntropy(from_logits=True)\n",
        "        else:\n",
        "            return tfa.losses.SigmoidFocalCrossEntropy(from_logits=False)"
      ],
      "metadata": {
        "id": "LTgAhvn-MrWi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Creating ontology heirarchy')\n",
        "direct_data = pd.read_csv(\n",
        "    direct_parent, delimiter=\"\\t\",\n",
        "    names=['Child', 'Parent']).replace({\"_\": \":\"}, regex=True)\n",
        "direct_data = direct_data.drop(0).reset_index(drop=True)\n",
        "onto_digraph = nx.from_pandas_edgelist(\n",
        "    direct_data, source='Child', target='Parent',\n",
        "    create_using=nx.classes.digraph.DiGraph)\n",
        "onto_info = \"Number of nodes: {0}\\nNumber of edges: {1}\".format(\n",
        "    onto_digraph.number_of_nodes(),\n",
        "    onto_digraph.number_of_edges(),\n",
        ")\n",
        "print(onto_info)\n",
        "logger.info(onto_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2kBKGQOMy4e",
        "outputId": "ad20d3c5-1adf-41ab-ea93-323a7cced2d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 50860\n",
            "Number of edges: 77512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Creating list of subsumers')\n",
        "subsumers = dict(\n",
        "    (i, list(\n",
        "        set(np.array(dfs_tree(onto_digraph, i).edges()).flatten().tolist()\n",
        "            + [i]) - set([\"owl:Thing\"])\n",
        "        )) for i in onto_digraph.nodes())"
      ],
      "metadata": {
        "id": "D7Ay_sM5M_yv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Parameters and hyperparameters for model training')\n",
        "config = {\n",
        "    \"weight\": 0.5,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 200,\n",
        "    \"batch_size\": 64,\n",
        "    \"activation\": 'softmax', \n",
        "    \"rdropout\": 0.3,\n",
        "    \"optimizer\": 'adamw',\n",
        "    \"loss\": 'sigfocalCE',\n",
        "    \"callbacks\": [\n",
        "        {\n",
        "            \"early_stop\": tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=10,\n",
        "                verbose=1,\n",
        "                restore_best_weights=True)\n",
        "        },\n",
        "    ],\n",
        "    \"learning_rate_func\": 'cosinedecay',\n",
        "    \"max_len\": 71,\n",
        "    \"max_char_len\": 15,\n",
        "    \"min_sent_len\": 3,\n",
        "    \"project\": \"Intelligent_OA\",\n",
        "    \"extra_info\": \"CRAFT, inputs: Word(30D), POS(100D)\",\n",
        "    \"dropout\": 0.5,\n",
        "    \"name\": \"CRAFT\"\n",
        "}\n",
        "print(config)\n",
        "logger.info(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td7xStgBNChM",
        "outputId": "e31fcbf7-74fc-4789-f35b-0a72904faa31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'weight': 0.5, 'learning_rate': 0.001, 'epochs': 200, 'batch_size': 64, 'activation': 'softmax', 'rdropout': 0.3, 'optimizer': 'adamw', 'loss': 'sigfocalCE', 'callbacks': [{'early_stop': <keras.callbacks.EarlyStopping object at 0x7f02f7b8c1d0>}], 'learning_rate_func': 'cosinedecay', 'max_len': 71, 'max_char_len': 15, 'min_sent_len': 3, 'project': 'Intelligent_OA', 'extra_info': 'CRAFT, inputs: Word(30D), POS(100D)', 'dropout': 0.5, 'name': 'CRAFT'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = json.load(open(os.path.join(DATASET_LOC, \"train.json\"), \"r\"))\n",
        "train_data = [\n",
        "    i for i in train_data if len(i['tokens']) >= config.get(\"min_sent_len\")\n",
        "]\n",
        "\n",
        "test_data = json.load(open(os.path.join(DATASET_LOC, \"test.json\"), \"r\"))\n",
        "test_data = [\n",
        "    i for i in test_data if len(i['tokens']) >= config.get(\"min_sent_len\")\n",
        "]\n",
        "input_data = train_data + test_data\n",
        "\n",
        "all_data = {\n",
        "    \"tokens\": [i['tokens'] for i in input_data],\n",
        "    \"tags\": [i['iob_tags'] for i in input_data],\n",
        "    \"pos\": [i['pos_tags'] for i in input_data],\n",
        "}\n",
        "assert (\n",
        "    len(all_data['tokens'])\n",
        "    == len(all_data['tags'])\n",
        "    == len(all_data['pos'])\n",
        ")"
      ],
      "metadata": {
        "id": "nqDbMvVzNFDw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Creating training and test dataset')\n",
        "logger.info('Creating training and test dataset')\n",
        "words = [\"PAD\"] + sorted(\n",
        "    set([j for i in all_data['tokens'] for j in i] + [\"UNK\", \"O\"])\n",
        "    - set([\"PAD\"]))\n",
        "tags = [\"PAD\"] + sorted(\n",
        "    set([j for i in all_data['tags'] for j in i] + [\"UNK\", \"O\"])\n",
        "    - set([\"PAD\"]))\n",
        "chars = [\"PAD\"] + sorted(\n",
        "    set([j for i in words for j in i] + [\"UNK\", \"O\"])\n",
        "    - set([\"PAD\"]))\n",
        "pos = [\"PAD\"] + sorted(\n",
        "    set([j for i in all_data['pos'] for j in i] + [\"UNK\", \"O\"])\n",
        "    - set([\"PAD\"]))\n",
        "\n",
        "n_words, n_tags, n_chars, = len(words), len(tags), len(chars)\n",
        "n_pos = len(pos)\n",
        "\n",
        "corpus_info = (\n",
        "    \"\\nNumber of Observations:{0}\\nNumber of words:{1}\"\n",
        "    \"\\nNumber of tags:{2}\\nNumber of characters: {3}\"\n",
        "    \"\\nNumber of pos: {4}\".format(\n",
        "        len(all_data['tokens']), n_words, n_tags, n_chars, n_pos)\n",
        "    )\n",
        "print(corpus_info)\n",
        "logger.info(corpus_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS3dUtejNILJ",
        "outputId": "d83f7480-8b1e-4b2a-b071-c963e941fedd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating training and test dataset\n",
            "\n",
            "Number of Observations:28880\n",
            "Number of words:34194\n",
            "Number of tags:1775\n",
            "Number of characters: 158\n",
            "Number of pos: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_idx = dict((i, idx) for idx, i in enumerate(words))\n",
        "idx_to_word = dict((v, k) for k, v in word_to_idx.items())\n",
        "\n",
        "tag_to_idx = dict((i, idx) for idx, i in enumerate(tags))\n",
        "idx_to_tag = dict((v, k) for k, v in tag_to_idx.items())\n",
        "\n",
        "char_to_idx = dict((i, idx) for idx, i in enumerate(chars))\n",
        "idx_to_char = dict((v, k) for k, v in char_to_idx.items())\n",
        "\n",
        "pos_to_idx = dict((i, idx) for idx, i in enumerate(pos))\n",
        "idx_to_pos = dict((v, k) for k, v in pos_to_idx.items())"
      ],
      "metadata": {
        "id": "MqEVHrLQNLd7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Creating output labels: one hot encodings')\n",
        "print('Creating output labels: one hot encodings')\n",
        "Y_tags = [[tag_to_idx.get(i) for i in sent] for sent in all_data['tags']]\n",
        "Y_tags = pad_sequences(\n",
        "    maxlen=config.get(\"max_len\"), sequences=Y_tags,\n",
        "    value=tag_to_idx.get(\"PAD\"), padding='post',\n",
        "    truncating='post', dtype='float16')\n",
        "Y_tags = to_categorical(Y_tags, num_classes=n_tags, dtype='float16')\n",
        "\n",
        "logger.info('Creating semantic embedding from subsumers information')\n",
        "print('Creating semantic embedding from subsumers information')\n",
        "sem_dist = dict(\n",
        "    [(i, to_categorical(i, num_classes=n_tags)) for i in range(n_tags)])\n",
        "factor = 0\n",
        "for i in range(n_tags):\n",
        "    iob_i = None\n",
        "    term_i = idx_to_tag.get(i)\n",
        "    if \"B-\" in term_i or \"I-\" in term_i:\n",
        "        iob_i = term_i[0]\n",
        "    term_i = term_i.replace(\"B-\", \"\").replace(\"I-\", \"\")\n",
        "    if \"GO\" in term_i:\n",
        "        sem_scores = []\n",
        "        for j in range(n_tags):\n",
        "            iob_j = None\n",
        "            term_j = idx_to_tag.get(j)\n",
        "            if \"B-\" in term_j or \"I-\" in term_j:\n",
        "                iob_j = term_j[0]\n",
        "            term_j = term_j.replace(\"B-\", \"\").replace(\"I-\", \"\")\n",
        "            score = config.get('weight') * get_sim(term_i, term_j)\n",
        "            if iob_i != iob_j:\n",
        "                score = factor * score\n",
        "            sem_scores.append(score)\n",
        "        sem_scores = np.array(sem_scores)\n",
        "        sem_scores[i] = 1\n",
        "        sem_dist[i] = sem_scores\n",
        "\n",
        "for i in range(n_tags):\n",
        "    num_max = np.where(sem_dist[i] == 1)[0].size\n",
        "    assert num_max == 1\n",
        "\n",
        "for i in range(len(Y_tags)):\n",
        "    for j in range(config.get(\"max_len\")):\n",
        "        k = np.where(Y_tags[i][j] == 1)[0][0]\n",
        "        Y_tags[i][j] = sem_dist[k]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA-hfjWsNPaV",
        "outputId": "686be613-87a7-4e91-e96d-6cc0ba5f0f8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating output labels: one hot encodings\n",
            "Creating semantic embedding from subsumers information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Creating input dataset')\n",
        "print('Creating input dataset')\n",
        "X_word = [[word_to_idx.get(w) for w in s] for s in all_data['tokens']]\n",
        "X_word = pad_sequences(\n",
        "    maxlen=config.get(\"max_len\"), sequences=X_word,\n",
        "    value=word_to_idx[\"PAD\"], padding='post', truncating='post',\n",
        "    dtype='float16')\n",
        "\n",
        "X_char_temp = []\n",
        "for wds in all_data['tokens']:\n",
        "    wds = wds[:config.get(\"max_len\")] + [\"PAD\"]*(\n",
        "        config.get(\"max_len\") - len(wds))\n",
        "    chrs = [list(word)[:config.get(\"max_char_len\")] + [\"PAD\"]*(\n",
        "        config.get(\"max_char_len\")-len(word))\n",
        "        if word != \"PAD\" else [\"PAD\"]*config.get(\"max_char_len\")\n",
        "        for word in wds]\n",
        "    X_char_temp.append(np.array(chrs))\n",
        "X_char_temp = np.array(X_char_temp)\n",
        "X_char = np.vectorize(char_to_idx.get)(X_char_temp).astype('float16')\n",
        "del X_char_temp\n",
        "\n",
        "X_pos = [[pos_to_idx.get(w) for w in s] for s in all_data['pos']]\n",
        "X_pos = pad_sequences(\n",
        "    maxlen=config.get(\"max_len\"), sequences=X_pos,\n",
        "    value=pos_to_idx.get(\"PAD\"), padding='post', truncating='post',\n",
        "    dtype='float16')\n",
        "\n",
        "max_idx = 0\n",
        "for i in range(len(X_word), 0, -1):\n",
        "    if (\n",
        "        i * 0.7 % config.get(\"batch_size\") == 0 and\n",
        "        i * 0.3 % config.get(\"batch_size\") == 0\n",
        "    ):\n",
        "        max_idx = i\n",
        "        break\n",
        "\n",
        "combined = [(X_word[i], X_char[i], X_pos[i]) for i in range(max_idx)]\n",
        "Y_tags = Y_tags[:max_idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu3wK4tNNWFz",
        "outputId": "f08df264-a982-472d-ccf1-1faccbeac1d6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating input dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Dividing dataset into 80-20 split')\n",
        "print('Dividing dataset into 80-20 split')\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    combined, Y_tags, test_size=0.3, random_state=2022)\n",
        "\n",
        "input_train = []\n",
        "for i in range(len(combined[0])):\n",
        "    temp = []\n",
        "    for j in range(len(X_tr)):\n",
        "        temp.append(X_tr[j][i])\n",
        "    input_train.append(np.array(temp, dtype='float16'))\n",
        "input_train = tuple(input_train)\n",
        "\n",
        "input_test = []\n",
        "for i in range(len(combined[0])):\n",
        "    temp = []\n",
        "    for j in range(len(X_te)):\n",
        "        temp.append(X_te[j][i])\n",
        "    input_test.append(np.array(temp, dtype='float16'))\n",
        "input_test = tuple(input_test)\n",
        "\n",
        "X_train_dataset = tf.data.Dataset.from_tensor_slices(input_train)\n",
        "X_test_dataset = tf.data.Dataset.from_tensor_slices(input_test)\n",
        "Y_train_dataset = tf.data.Dataset.from_tensor_slices(y_tr)\n",
        "Y_test_dataset = tf.data.Dataset.from_tensor_slices(y_te)\n",
        "\n",
        "train_dataset = tf.data.Dataset.zip((X_train_dataset, Y_train_dataset))\n",
        "test_dataset = tf.data.Dataset.zip((X_test_dataset, Y_test_dataset))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(1000).batch(config['batch_size'])\n",
        "test_dataset = test_dataset.batch(config['batch_size'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ems7_u9UNYih",
        "outputId": "436a7e98-ec58-44f1-bd21-13957c53798f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dividing dataset into 80-20 split\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Defining deep learning architecture')\n",
        "print('Defining deep learning architecture')\n",
        "\n",
        "# input and embedding for words\n",
        "word_in = Input(\n",
        "    shape=(config.get(\"max_len\"),), name=\"WORD\")\n",
        "emb_word = Embedding(\n",
        "    input_dim=n_words, output_dim=30,\n",
        "    input_length=config.get(\"max_len\"), mask_zero=True)(word_in)\n",
        "\n",
        "# input and embeddings for characters\n",
        "char_in = Input(\n",
        "    shape=(config.get(\"max_len\"), config.get(\"max_char_len\"),),\n",
        "    name=\"CHAR\")\n",
        "emb_char = TimeDistributed(\n",
        "    Embedding(\n",
        "        input_dim=n_chars, output_dim=100,\n",
        "        input_length=config.get(\"max_char_len\"),\n",
        "        mask_zero=True))(char_in)\n",
        "char_enc = TimeDistributed(\n",
        "    GRU(\n",
        "        units=150, return_sequences=False, recurrent_dropout=0.5)\n",
        "        )(emb_char)\n",
        "\n",
        "# input and embeddings for pos\n",
        "pos_in = Input(shape=(config.get(\"max_len\"),), name=\"POS\")\n",
        "emb_pos = Embedding(\n",
        "    input_dim=n_pos, output_dim=100, input_length=config.get(\"max_len\"),\n",
        "    mask_zero=True, name=\"EMB_POS\")(pos_in)\n",
        "\n",
        "# main LSTM\n",
        "x = concatenate([emb_word, char_enc, emb_pos])\n",
        "x = SpatialDropout1D(config.get(\"dropout\"))(x)\n",
        "main_lstm = Bidirectional(\n",
        "    GRU(\n",
        "        units=150, return_sequences=True,\n",
        "        recurrent_dropout=config['rdropout']))(x)\n",
        "main_lstm = TimeDistributed(Dense(3200, activation='relu'))(main_lstm)\n",
        "main_lstm = Dropout(config.get(\"dropout\"))(main_lstm)\n",
        "out = TimeDistributed(\n",
        "    Dense(\n",
        "        n_tags, activation=config['activation']\n",
        "    ), name=\"OUT_TAGS\")(main_lstm)\n",
        "\n",
        "model = Model([word_in, char_in, pos_in], out)\n",
        "model.compile(\n",
        "    optimizer=get_optimizer(config['optimizer'], config['learning_rate']),\n",
        "    loss=get_loss(config['loss']), metrics=[\"acc\"])\n",
        "print(model.summary())\n",
        "logger.info(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oiCqecuNcLd",
        "outputId": "008f7360-acff-458b-95cc-443c5d89820b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defining deep learning architecture\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " CHAR (InputLayer)              [(None, 71, 15)]     0           []                               \n",
            "                                                                                                  \n",
            " WORD (InputLayer)              [(None, 71)]         0           []                               \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 71, 15, 100)  15800      ['CHAR[0][0]']                   \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " POS (InputLayer)               [(None, 71)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 71, 30)       1025820     ['WORD[0][0]']                   \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, 71, 150)     113400      ['time_distributed[0][0]']       \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " EMB_POS (Embedding)            (None, 71, 100)      5000        ['POS[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 71, 280)      0           ['embedding[0][0]',              \n",
            "                                                                  'time_distributed_1[0][0]',     \n",
            "                                                                  'EMB_POS[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d (SpatialDrop  (None, 71, 280)     0           ['concatenate[0][0]']            \n",
            " out1D)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 71, 300)      388800      ['spatial_dropout1d[0][0]']      \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, 71, 3200)    963200      ['bidirectional[0][0]']          \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 71, 3200)     0           ['time_distributed_2[0][0]']     \n",
            "                                                                                                  \n",
            " OUT_TAGS (TimeDistributed)     (None, 71, 1775)     5681775     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,193,795\n",
            "Trainable params: 8,193,795\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " CHAR (InputLayer)              [(None, 71, 15)]     0           []                               \n",
            "                                                                                                  \n",
            " WORD (InputLayer)              [(None, 71)]         0           []                               \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 71, 15, 100)  15800      ['CHAR[0][0]']                   \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " POS (InputLayer)               [(None, 71)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 71, 30)       1025820     ['WORD[0][0]']                   \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, 71, 150)     113400      ['time_distributed[0][0]']       \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " EMB_POS (Embedding)            (None, 71, 100)      5000        ['POS[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 71, 280)      0           ['embedding[0][0]',              \n",
            "                                                                  'time_distributed_1[0][0]',     \n",
            "                                                                  'EMB_POS[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d (SpatialDrop  (None, 71, 280)     0           ['concatenate[0][0]']            \n",
            " out1D)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 71, 300)      388800      ['spatial_dropout1d[0][0]']      \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, 71, 3200)    963200      ['bidirectional[0][0]']          \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 71, 3200)     0           ['time_distributed_2[0][0]']     \n",
            "                                                                                                  \n",
            " OUT_TAGS (TimeDistributed)     (None, 71, 1775)     5681775     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,193,795\n",
            "Trainable params: 8,193,795\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_arch = tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "ONNKWmNGNo0V"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Starting model training')\n",
        "print('Starting model training')\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    epochs=config['epochs'],\n",
        "    validation_data=test_dataset,\n",
        "    verbose=1,\n",
        "    callbacks=[v for i in config.get(\"callbacks\") for v in i.values()]\n",
        ")\n",
        "\n",
        "print('Model training complete')\n",
        "logger.info('Model training complete')"
      ],
      "metadata": {
        "id": "wx31_2bfNrkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_word, X_char, X_pos, Y_tags, combined, input_train, X_train_dataset\n",
        "del Y_train_dataset, train_dataset"
      ],
      "metadata": {
        "id": "N5bOjJs2NzUQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Making predictions')\n",
        "pred = []\n",
        "step = 100\n",
        "pbar = tqdm(total=len(X_te), desc=\"Making predictions:\")\n",
        "for i in range(int(len(X_te)/step)+1):\n",
        "    inp = [j[i*step:(i+1)*step] for j in input_test]\n",
        "    if inp[0].shape[0] != 0:\n",
        "        temp = model.predict(inp)\n",
        "    pred.append(temp)\n",
        "    pbar.update(temp.shape[0])\n",
        "pred = np.concatenate(pred)\n",
        "pbar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4S676m8NyHQ",
        "outputId": "2e544709-311e-4cf3-cb30-83a119ed6e77"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:: 100%|██████████| 8640/8640 [00:27<00:00, 316.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Calculating F1 score and semantic similarity scores')\n",
        "word = np.vectorize(idx_to_word.get)(input_test[0]).flatten()\n",
        "ground_truth = np.vectorize(idx_to_tag.get)(\n",
        "    np.argmax(y_te, axis=-1)).flatten()\n",
        "predictions = (np.vectorize(idx_to_tag.get)(\n",
        "    np.argmax(pred, axis=-1))).flatten().tolist()\n",
        "two_predictions = (np.vectorize(idx_to_tag.get)(\n",
        "    np.argsort(-1*pred, axis=-1)[:, :, :2])).reshape(\n",
        "        pred.shape[0]*pred.shape[1], 2).tolist()"
      ],
      "metadata": {
        "id": "LOEpkEorOwdi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_data = pd.DataFrame({\n",
        "    \"Word\": word,\n",
        "    \"Ground_Truth\": ground_truth,\n",
        "    \"Prediction\": predictions,\n",
        "    \"Top_Two_Predictions\": two_predictions,\n",
        "})"
      ],
      "metadata": {
        "id": "aaUuH250PG_g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ajGjV6zotjdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786c96dd-e366-41f6-dfbf-03841c0a48f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'IOB_F1': '0.1119', 'IOB_Sim': 0.1384}\n",
            "{'F1': '0.1221', 'Sim': 0.1384}\n",
            "{'F1_Top_2': '0.0478', 'Sim_Top_2': 0.2032}\n"
          ]
        }
      ],
      "source": [
        "pd_data.drop(pd_data[pd_data['Ground_Truth'] == \"PAD\"].index, inplace=True)\n",
        "pd_data.drop(\n",
        "    pd_data[\n",
        "        (pd_data[\"Ground_Truth\"] == \"O\") &\n",
        "        (pd_data[\"Prediction\"] == \"O\")\n",
        "    ].index, inplace=True)\n",
        "pd_data.drop(\n",
        "    pd_data[\n",
        "        (pd_data[\"Ground_Truth\"] == \"EOS\") &\n",
        "        (pd_data[\"Prediction\"] == \"EOS\")\n",
        "    ].index, inplace=True)\n",
        "\n",
        "pd_data['Comparison'] = pd_data.apply(\n",
        "    lambda x: x[1] if x[1] in x[-1] else x[-1][-1], axis=1)\n",
        "\n",
        "logger.info('Creating classification report')\n",
        "top_report = classification_report(\n",
        "    pd_data['Ground_Truth'],\n",
        "    pd_data['Prediction'],\n",
        "    zero_division=False,\n",
        "    digits=4,\n",
        ")\n",
        "# print(top_report)\n",
        "score_iob = ({\n",
        "    \"IOB_F1\": top_report.splitlines()[-1].split()[-2],\n",
        "    \"IOB_Sim\": np.round(\n",
        "        pd_data[['Prediction', 'Ground_Truth']].apply(\n",
        "            lambda x: get_sim(x[0], x[1]), axis=1).mean(), 4)\n",
        "})\n",
        "print(score_iob)\n",
        "logger.info(score_iob)\n",
        "df1 = pd_data.copy().replace({\"B-GO:\": \"GO:\", \"I-GO:\": \"GO:\"}, regex=True)\n",
        "report = classification_report(\n",
        "    df1['Ground_Truth'],\n",
        "    df1['Prediction'],\n",
        "    zero_division=False,\n",
        "    digits=4,\n",
        ")\n",
        "# print(report)\n",
        "score_top_one = ({\n",
        "    \"F1\": report.splitlines()[-1].split()[-2],\n",
        "    \"Sim\": np.round(\n",
        "        df1[['Prediction', 'Ground_Truth']].apply(\n",
        "            lambda x: get_sim(x[0], x[1]), axis=1).mean(), 4)\n",
        "})\n",
        "print(score_top_one)\n",
        "logger.info(score_top_one)\n",
        "df2 = df1.copy()\n",
        "df2.drop(\n",
        "    df2[\n",
        "        (df2[\"Ground_Truth\"] == \"O\") &\n",
        "        (df2[\"Comparison\"] == \"O\")\n",
        "    ].index, inplace=True)\n",
        "df2.drop(\n",
        "    df2[\n",
        "        (df2[\"Ground_Truth\"] == \"EOS\") &\n",
        "        (df2[\"Comparison\"] == \"EOS\")\n",
        "    ].index, inplace=True)\n",
        "\n",
        "top_two_report = classification_report(\n",
        "    df2['Ground_Truth'],\n",
        "    df2['Comparison'],\n",
        "    zero_division=False,\n",
        "    digits=4,\n",
        ")\n",
        "# print(top_two_report)\n",
        "score_top_two = ({\n",
        "    \"F1_Top_2\": top_two_report.splitlines()[-1].split()[-2],\n",
        "    \"Sim_Top_2\": np.round(\n",
        "        df2[['Comparison', 'Ground_Truth']].apply(\n",
        "            lambda x: get_sim(x[0], x[1]), axis=1).mean(), 4)\n",
        "})\n",
        "print(score_top_two)\n",
        "logger.info(score_top_two)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ioQhUErrPO_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}